{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "import numpy as np\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "import os\n",
    "import json\n",
    "from nltk.corpus import wordnet\n",
    "import glob\n",
    "import csv\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read kwds list\n",
    "def read_kwd(txtfile):\n",
    "    f = open(txtfile)\n",
    "    content = f.read()\n",
    "    kw_list = (content.lower()).split('\\n')\n",
    "    return kw_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_synonym(voc_concept):\n",
    "    #Creating a list\n",
    "    synonyms = []\n",
    "    for syn in wordnet.synsets(voc_concept,lang='fra'):#, lang='fra'\n",
    "        for lm in syn.lemmas('fra'):\n",
    "            synonyms.append(lm.name())#adding into synonyms\n",
    "    synonyms = set(synonyms)\n",
    "    return synonyms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = ['incendie', 'eau']\n",
    "def retriev_syno(voc_concept):\n",
    "    data = read_kwd(voc_concept)\n",
    "    root, filname = os.path.split(voc_concept)\n",
    "    filname = filname.split('.txt')[0]\n",
    "    synos = {}\n",
    "    for t in data:\n",
    "        synos[t] = []\n",
    "        ts = t.split(' ')\n",
    "        if ts.__len__() == 1:\n",
    "            syn1 = [get_synonym(a) for a in ts]\n",
    "            syn1[0] = [v for v in list(syn1[0]) if v!=t]\n",
    "            synos[t] = list(syn1[0])\n",
    "        if ts.__len__() > 1:\n",
    "            syn = [get_synonym(a) for a in ts]\n",
    "#             print(syn)\n",
    "            for s in syn[0]:\n",
    "                test = \" \".join(ts[1:])\n",
    "                w = s.lower() + ' ' + test\n",
    "#                 print(w)\n",
    "                if w != t:\n",
    "                    synos[t].append(w)\n",
    "#     print(synos)\n",
    "    return synos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expert_terms_nature_danger = './Herelles_ress/termes_graines_natural.dangers.txt'\n",
    "expert_terms_urban = \"./Herelles_ress/termes_graines_urbanisme.txt\"\n",
    "expert_terms_synos = retriev_syno(expert_terms_urban)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# dic = {'a': ['ACI', 'BBY', 'AMRX'], 'b': ['A;BM', 'AG']} \n",
    "df = pd.DataFrame.from_dict(expert_terms_synos, orient='index').T #Convert dict to df\n",
    "# print(df)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"./Herelles_ress/termes_graines_urbanisme_extend.csv\",header=True) #Convert df to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List data to csv file\n",
    "def write_list_to_txt(terms_list, outfile):\n",
    "    \"\"\"Write the list to csv file.\"\"\"\n",
    "    with open(outfile, 'w') as f:\n",
    "        for item in terms_list:\n",
    "            f.write(\"%s\\n\" % item)\n",
    "    return outfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# recoder pour prendre en compte un fichier csv, la sortie du vocabulaire de concepts final\n",
    "def generate_new_terms(voc_concept):\n",
    "    data = read_kwd(voc_concept)\n",
    "    root, filname = os.path.split(voc_concept)\n",
    "    filname = filname.split('.txt')[0]\n",
    "    L = []\n",
    "    for t in data:\n",
    "        t = t.split(' ')\n",
    "        if t.__len__() == 1:\n",
    "            syn = [get_synonym(a) for a in t]\n",
    "            for v in syn[0]:\n",
    "                L.append(v)\n",
    "        if t.__len__() > 1:\n",
    "            syn = [get_synonym(a) for a in t]\n",
    "            #print(syn)\n",
    "            for s in syn[0]:\n",
    "                test = \" \".join(t[1:])\n",
    "                w = s.lower() + ' ' + test\n",
    "                #print('zzz', w)\n",
    "                L.append(w)\n",
    "    #print(L.__len__())\n",
    "    L = set(L)\n",
    "    #print(L.__len__())\n",
    "#     write_list_to_txt(L,filname+'_syno.txt')\n",
    "    return list(L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# usage\n",
    "data = './Herelles_ress/termes_graines_natural.dangers.txt'\n",
    "# extended_data = generate_new_terms(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
